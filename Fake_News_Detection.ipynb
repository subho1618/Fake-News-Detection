{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import Libraries and Dataset"
      ],
      "metadata": {
        "id": "Ke2-7dUkhXB_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "96yDD1SlhSUK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('News.csv',index_col=0)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "e0bWnS5WheMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing"
      ],
      "metadata": {
        "id": "2m4uTdN5h82A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "IGs7tHBFh-r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop([\"title\", \"subject\",\"date\"], axis = 1)"
      ],
      "metadata": {
        "id": "nMT5Er8IiA4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "21jnI1uSiDmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling\n",
        "data = data.sample(frac=1)\n",
        "data.reset_index(inplace=True)\n",
        "data.drop([\"index\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "wyaWmzMjiG3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=data,\n",
        "\t\t\tx='class',\n",
        "\t\t\torder=data['class'].value_counts().index)\n"
      ],
      "metadata": {
        "id": "zrScMos3iJxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing and analysis of News Column"
      ],
      "metadata": {
        "id": "nw-AhsfJiOTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "Zd0mPzCbiSfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text_data):\n",
        "\tpreprocessed_text = []\n",
        "\n",
        "\tfor sentence in tqdm(text_data):\n",
        "\t\tsentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
        "\t\tpreprocessed_text.append(' '.join(token.lower()\n",
        "\t\t\t\t\t\t\t\tfor token in str(sentence).split()\n",
        "\t\t\t\t\t\t\t\tif token not in stopwords.words('english')))\n",
        "\n",
        "\treturn preprocessed_text\n"
      ],
      "metadata": {
        "id": "MPuQFau9iVKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_review = preprocess_text(data['text'].values)\n",
        "data['text'] = preprocessed_review"
      ],
      "metadata": {
        "id": "lzg1IDFciYdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real\n",
        "consolidated = ' '.join(\n",
        "\tword for word in data['text'][data['class'] == 1].astype(str))\n",
        "wordCloud = WordCloud(width=1600,\n",
        "\t\t\t\t\theight=800,\n",
        "\t\t\t\t\trandom_state=21,\n",
        "\t\t\t\t\tmax_font_size=110,\n",
        "\t\t\t\t\tcollocations=False)\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MJnipxQtibxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake\n",
        "consolidated = ' '.join(\n",
        "\tword for word in data['text'][data['class'] == 0].astype(str))\n",
        "wordCloud = WordCloud(width=1600,\n",
        "\t\t\t\t\theight=800,\n",
        "\t\t\t\t\trandom_state=21,\n",
        "\t\t\t\t\tmax_font_size=110,\n",
        "\t\t\t\t\tcollocations=False)\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nI0C_FGtigt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "def get_top_n_words(corpus, n=None):\n",
        "\tvec = CountVectorizer().fit(corpus)\n",
        "\tbag_of_words = vec.transform(corpus)\n",
        "\tsum_words = bag_of_words.sum(axis=0)\n",
        "\twords_freq = [(word, sum_words[0, idx])\n",
        "\t\t\t\tfor word, idx in vec.vocabulary_.items()]\n",
        "\twords_freq = sorted(words_freq, key=lambda x: x[1],\n",
        "\t\t\t\t\t\treverse=True)\n",
        "\treturn words_freq[:n]\n",
        "\n",
        "\n",
        "common_words = get_top_n_words(data['text'], 20)\n",
        "df1 = pd.DataFrame(common_words, columns=['Review', 'count'])\n",
        "\n",
        "df1.groupby('Review').sum()['count'].sort_values(ascending=False).plot(\n",
        "\tkind='bar',\n",
        "\tfigsize=(10, 6),\n",
        "\txlabel=\"Top Words\",\n",
        "\tylabel=\"Count\",\n",
        "\ttitle=\"Bar Chart of Top Words Frequency\"\n",
        ")"
      ],
      "metadata": {
        "id": "_n0WwJ9mikWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting text into Vectors"
      ],
      "metadata": {
        "id": "xXVPGUOsinBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['text'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tdata['class'],\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size=0.25)\n"
      ],
      "metadata": {
        "id": "opEfQ5KRir28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorization = TfidfVectorizer()\n",
        "x_train = vectorization.fit_transform(x_train)\n",
        "x_test = vectorization.transform(x_test)\n"
      ],
      "metadata": {
        "id": "cWNDjJkYitsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# testing the model\n",
        "print(accuracy_score(y_train, model.predict(x_train)))\n",
        "print(accuracy_score(y_test, model.predict(x_test)))\n"
      ],
      "metadata": {
        "id": "jFMgo5iGixGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# testing the model\n",
        "print(accuracy_score(y_train, model.predict(x_train)))\n",
        "print(accuracy_score(y_test, model.predict(x_test)))\n"
      ],
      "metadata": {
        "id": "TN39QuxGizKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix of Results from Decision Tree classification\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(y_test, model.predict(x_test))\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "\t\t\t\t\t\t\t\t\t\t\tdisplay_labels=[False, True])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MVNtYIO_ixyb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}